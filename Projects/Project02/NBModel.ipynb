{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0326de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yelp = pd.read_json('./yelp_dataset/yelp_academic_dataset_review.json', lines=True, nrows=100000)\n",
    "# yelp = pd.read_json('./yelp_dataset/yelp_academic_dataset_review.json', lines=True)\n",
    "yelp['text'] = yelp['text'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b7eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import numpy as np\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "reviews = [fake.paragraph() for _ in range(10000)]\n",
    "\n",
    "# create a list of random stars for the reviews\n",
    "stars = np.random.choice([1, 2, 3, 4, 5], size=10000)\n",
    "\n",
    "# create a list of random number of useful, funny, and cool votes for the reviews\n",
    "useful = np.random.randint(1, 5, size=10000)\n",
    "funny = np.random.randint(1, 5, size=10000)\n",
    "cool = np.random.randint(1, 5, size=10000)\n",
    "\n",
    "fake_yelp = pd.DataFrame({'text': reviews,\n",
    "                     'stars': stars,\n",
    "                     'useful': useful,\n",
    "                     'funny': funny,\n",
    "                     'cool': cool})\n",
    "\n",
    "# yelp = fake_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0a1452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77405\n",
      "0.58635\n",
      "0.85195\n",
      "0.7986\n",
      "Table For Naive Bayes Probabilistic Classifier\n",
      "  Score (Stars)    Score (Useful)    Score (Funny)    Score (Cool)\n",
      "---------------  ----------------  ---------------  --------------\n",
      "        0.77405           0.58635          0.85195          0.7986\n",
      "Elapsed time:  6.532774925231934  seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "class NBClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_trained_data(self, x, target_data):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, target_data, train_size=0.8) \n",
    "        # X_valid, X_test, y_valid, y_test = train_test_split(X_remaining, y_remaining, test_size=0.5)\n",
    "\n",
    "        # Train the Naive Bayes classifier\n",
    "        nb_classifier = MultinomialNB(alpha = 0.1)\n",
    "        nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the sentiment for the test data\n",
    "        y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "        # Evaluate the performance of the classifier\n",
    "        print(metrics.accuracy_score(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "input_columns = ['text']\n",
    "irrelevant_columns = ['review_id', 'user_id', 'business_id', 'date']\n",
    "output_columns = ['stars', 'useful', 'funny', 'cool']\n",
    "\n",
    "# ############## EXPERIMENT 2\n",
    "# half_size = len(yelp.index) // 2\n",
    "# rand_indices = np.random.choice(yelp.index, half_size, replace=False)\n",
    "\n",
    "# # update the selected rows to have a value of 1\n",
    "# yelp.loc[rand_indices, \"stars\"] = 1\n",
    "# ############## EXPERIMENT 2\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "x = yelp.drop(columns=output_columns)\n",
    "v = CountVectorizer(ngram_range=(1, 1))\n",
    "x = v.fit_transform(x['text'])\n",
    "\n",
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(x)\n",
    "\n",
    "x = unigram_tf_idf_transformer.transform(x)\n",
    "y = yelp.drop(columns=input_columns)\n",
    "\n",
    "nb_stars = NBClassifier()\n",
    "nb_useful = NBClassifier()\n",
    "nb_funny = NBClassifier()\n",
    "nb_cool = NBClassifier()\n",
    "\n",
    "nb_stars_score = nb_stars.get_trained_data(x, y[\"stars\"])\n",
    "nb_useful_score = nb_useful.get_trained_data(x, y[\"useful\"])\n",
    "nb_funny_score = nb_funny.get_trained_data(x, y[\"funny\"])\n",
    "nb_cool_score = nb_cool.get_trained_data(x, y[\"cool\"])\n",
    "\n",
    "table_MultinomialNB = ['Score (Stars)', 'Score (Useful)', 'Score (Funny)', 'Score (Cool)'], [nb_stars_score, nb_useful_score, nb_funny_score, nb_cool_score]\n",
    "\n",
    "print('Table For Naive Bayes Probabilistic Classifier')\n",
    "print(tabulate(table_MultinomialNB, headers='firstrow'))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \", elapsed_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b095a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca09f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
