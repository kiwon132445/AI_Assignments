{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Text Classification with Naïve Bayes\n",
    "This notebook serves as the starter code and lab description covering **Chapter 12 - Quantifying Uncertainty** and **Chapter 13 - Probabilistic Reasoning** from the book *Artificial Intelligence: A Modern Approach.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install sklearn\n",
    "# pip install numpy\n",
    "\n",
    "from starter import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This function is placed here to help you read through the source code of different classes, \n",
    "#  and debug what has been loaded into jupyter, \n",
    "#  make sure all the function calls to `psource` are commented in your submission\n",
    "def psource(*functions):\n",
    "    \"\"\"Print the source code for the given function(s).\"\"\"\n",
    "    from inspect import getsource\n",
    "    source_code = '\\n\\n'.join(getsource(fn) for fn in functions)\n",
    "    try:\n",
    "        from pygments.formatters import HtmlFormatter\n",
    "        from pygments.lexers import PythonLexer\n",
    "        from pygments import highlight\n",
    "        from IPython.display import HTML\n",
    "\n",
    "        display(HTML(highlight(source_code, PythonLexer(), HtmlFormatter(full=True))))\n",
    "\n",
    "    except ImportError:\n",
    "        print(source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW\n",
    "In this lab, you will partially implement a Naïve Bayes text classifier which looks at SMS text messages and categorizes them into two classes of **ham** vs. **spam**. In this regards, we will learn how a probability distribution is implemented in terms of python code and how it can be extended to represent a joint probability distribution. Let's get started!\n",
    "\n",
    "### Data\n",
    "The data has been collected from free or free for research sources at the Internet ([Accessible Here](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)). The data format is very simple; it is a *.tsv* file containing 5,574 text messages from which 747 are spam and the other 4,827 are normal (ham) messages. \n",
    "\n",
    "Lets load up the dataset and look at the first text message and its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL                                                  ham\n",
       "TEXT     Go until jurong point, crazy.. Available only ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t', header=0)\n",
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have all the data loaded in one place, we need to speparate out a part of it for testing our model once its ready, use `train_test_split` function from *sklearn* library (which has already been loaded in the first cell), to speparate out a portion of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fill in this cell properly to have 10% of the data as test and the rest as train, \n",
    "# have train_test_split shuffle your data and use 42 as random seed.\n",
    "train, test = data, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the distribution of messages in our classes in the test and train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LABEL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEXT\n",
       "LABEL      \n",
       "ham    4340\n",
       "spam    674"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='LABEL').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LABEL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEXT\n",
       "LABEL      \n",
       "ham     485\n",
       "spam     73"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(by='LABEL').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our test set will contain enough instances of each class to help us evaluate both classes. Be careful about aggergation of accuracy scores for both classes though. Think what could go wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBABILITY DISTRIBUTION\n",
    "\n",
    "Let us continue by specifying discrete probability distributions. The class **ProbDist** defines a discrete probability distribution. We name our random variable and then assign probabilities to the different values of the random variable. Assigning probabilities to the values works similar to that of using a dictionary with keys being the Value and we assign to it the probability. This is possible because of the magic methods **_ _getitem_ _**  and **_ _setitem_ _** which store the probabilities in the prob dict of the object. You can keep the source window open alongside while playing with the rest of the code to get a better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psource(ProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a bit more comfortable with *ProbDist* define an instance of it which recevies a vocabulary containing the four words: {`cat`, `dog`, `hamster`, `rabbit`} with respective frequencies {417, 330, 240, 32}. Print out the probability of `hamster` happening in this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23552502453385674\n"
     ]
    }
   ],
   "source": [
    "# TODO using ProbDist find probability of 'hamster' happening in the vocabulary which should be equal to 0.23552502453385674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Probability Distribution\n",
    "\n",
    "A probability model is completely determined by the joint distribution for all of the random variables. The probability module implements these as the class **JointProbDist** which inherits from the **ProbDist** class. This class specifies a discrete probability distribute over a set of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#psource(JointProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Values* for a Joint Distribution is a an ordered tuple in which each item corresponds to the value associate with a particular variable. For Joint Distribution of X, Y where X, Y take integer values this can be something like (18, 19).\n",
    "\n",
    "To specify a Joint distribution we first need an ordered list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(['X', 'Y'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['X', 'Y']\n",
    "j = JointProbDist(variables)\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the **ProbDist** class **JointProbDist** also employes magic methods to assign probability to different values.\n",
    "The probability can be assigned in either of the two formats for all possible values of the distribution. The **event_values** call inside  **_ _getitem_ _**  and **_ _setitem_ _** does the required processing to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[1,1] = 0.2\n",
    "j[dict(X=0, Y=1)] = 0.5\n",
    "\n",
    "(j[1,1], j[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to list all the values for a particular variable using the **values** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.values('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification with Naïve Bayes\n",
    "We can get back to our task of text classification for SMS messages. As we discussed in the lecture, The Naïve Bayes model consists of the prior probabilities $\\textbf{P}(Category)$ and the conditional probabilities\n",
    "$\\textbf{P}(HasWord_i|Category)$. Here, our categories are clearly `ham` and `spam`. So first thing we should collect statistics about our categories.\n",
    "Make a *ProbDist* instance and fill it with $\\textbf{P}(Category)$ information. **You must only collect these information from your train data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham: 0.866, spam: 0.134'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.groupby(by='LABEL').agg('count').reset_index()\n",
    "ham_count = int(df.loc[df['LABEL']=='ham']['TEXT'].astype(int))\n",
    "# TODO continue from here and create p_category here using the train data\n",
    "# use show_approx function and make sure the probability of spam is not too low here (e.g. below 0.11) \n",
    "# if it was the case re-run the 'train_test_split' cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, $\\textbf{P}(HasWord_i|Category)$ is estimated as the fraction of\n",
    "documents of each category that contain word $i$. \n",
    "\n",
    "Using the knowledge of what you have learned and all of the code that has been provided to you in this lab so far, **collect/create $\\textbf{P}(HasWord_i|Category)$. Again, you must only collect these information using your train data**.\n",
    "\n",
    "Note that calculating $\\textbf{P}(HasWord_i|Category)$ means counting how many times the word with index $i$ appears in text messages in $Category$ of documents divided by the total number of words in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create p_has_word_category as a JointProbDist and fill it in by iterating through train instances\n",
    "# Implementation hint 1: you can iterate through the rows of pandas DataFrame using the function `iterrows`\n",
    "# Implementation hint 2: once you collected the joint word, category information, you must normalize \n",
    "#                        the collected counts and turn them to probability distributions over each category\n",
    "#                        i.e. the content of p_has_word_category for each category must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in p_has_word_category.values('Category'):\n",
    "    print(\"Sum probability for category {} should sum to 1. The actual summation is equal to {}.\".format(\n",
    "        c, sum((p_has_word_category[w, c] for w in p_has_word_category.values('HasWord')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together to classify test data\n",
    "Based on Equation 12.21 of the textbook, For an evidence $\\textbf{e}$ (or in our case an SMS message) we can calculate the probability of each $Category$ (both `ham` and `spam`) using the following equation in which $e_j$ is the $j$th word in our text message:\n",
    "\n",
    "$$\\textbf{P}(Category|\\textbf{e}) = \\alpha \\sum_y{\\textbf{P}(Category)\\textbf{P}(\\textbf{y}|Category)\\big(\\prod_j\\textbf{P}(e_j|Category)\\big)}$$\n",
    "$$= \\alpha \\textbf{P}(Category) \\big(\\prod_j\\textbf{P}(e_j|Category)\\big) \\sum_y \\textbf{P}(\\textbf{y}|Category)$$\n",
    "$$= \\alpha \\textbf{P}(Category) \\prod_j\\textbf{P}(e_j|Category)$$\n",
    "\n",
    "Your next task is to use the information you have created so far (and the equation we just reviewed) to classify the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_predicted_as_spam = 0.0\n",
    "spam_predicted_as_ham = 0.0\n",
    "ham_predicted_as_ham = 0.0\n",
    "ham_predicted_as_spam = 0.0\n",
    "total_ham = 0.0\n",
    "total_spam = 0.0\n",
    "# #############################################################################################\n",
    "# IMPORTANT! DO NOT MODIFY THE LINES ABOVE THIS LINE\n",
    "\n",
    "# TODO use the Naïve Bayes classification equation here to classify test data.\n",
    "# Implementation hint: simply use the two distributions you just collected and calculate P(ham|text_message) \n",
    "# and P(spam|text_message) and selected the one with higher probability as the message class.\n",
    "# once your prediction is ready for each instance, increment the proper equivalent values from the 6 values above\n",
    "# (for each instace only one *predicted_as* variable will be updated and one *total_* variable depending on\n",
    "# the actual test message label.\n",
    "\n",
    "# Once you are done with the implementation, running this cell will use your collected stats and print out the \n",
    "# confusion matrix and precision, recall, and f-1 scores of your classifier.\n",
    "    \n",
    "# IMPORTANT! DO NOT MODIFY THE LINES BELOW THIS LINE\n",
    "# #############################################################################################\n",
    "print(\"confusion matrix\\tprd_ham\\t\\tprd_spam\\nact_ham         \\t{}\\t\\t{}\\nact_spam        \\t{}\\t\\t{}\\n\".format(\n",
    "    ham_predicted_as_ham, ham_predicted_as_spam, spam_predicted_as_ham, spam_predicted_as_spam))\n",
    "acc_ham = ham_predicted_as_ham * 100 /total_ham\n",
    "acc_spam = spam_predicted_as_spam * 100 /total_spam\n",
    "rec_ham = ham_predicted_as_ham * 100 /(ham_predicted_as_ham+spam_predicted_as_ham)\n",
    "rec_spam = spam_predicted_as_spam * 100 /(spam_predicted_as_spam + ham_predicted_as_spam)\n",
    "f1_ham = 2 * acc_ham * rec_ham / (acc_ham + rec_ham)\n",
    "f1_spam = 2 * acc_spam * rec_spam / (acc_spam + rec_spam)\n",
    "print(\"Prediction accuracy\\tham = {:.3f}\\tspam = {:.3f}\".format(acc_ham, acc_spam))\n",
    "print(\"Prediction recall\\tham = {:.3f}\\tspam = {:.3f}\".format(rec_ham, rec_spam))\n",
    "print(\"Prediction F-1 score\\tham = {:.3f}\\tspam = {:.3f}\".format(f1_ham, f1_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Explain what can you understand from the results you just got. In particular, explain what do you get out of the results in confusion matrix and what do accuracy (precision), recall, and f-1 scores tell You?\n",
    "\n",
    "### Your Answer\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement\n",
    "Think of one thing that would be helpful to improve the accuracy of your implemented Naïve Bayes classifier. Implement it and use the same evaluation script to calculate the results and analyse its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement your improvement here and re-test it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
